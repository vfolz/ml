{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPL Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql.cursors\n",
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import qgrid\n",
    "import pw \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import model_from_json\n",
    "json_file = open('regressor.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "regressor = model_from_json(loaded_model_json)\n",
    "regressor.load_weights(\"regressor.h5\")\n",
    " \n",
    "grid_options={'forceFitColumns': False, 'defaultColumnWidth': 100, 'minVisibleRows': 10}\n",
    "\n",
    "connection = pymysql.connect(host=pw.srv,\n",
    "                         user=pw.usr,\n",
    "                         password=pw.pwrd,\n",
    "                         db=pw.db,\n",
    "                         charset='utf8mb4',\n",
    "                         cursorclass=pymysql.cursors.DictCursor)\n",
    "def cum_sum (df,groupby_lst,field):\n",
    "    df['temp'] = df.groupby(groupby_lst)[field].cumsum()\n",
    "    return df.groupby(groupby_lst)['temp'].shift(1).fillna(0)\n",
    "\n",
    "def rolled_mean (df,groupby_lst,field, n_months, num_shift):\n",
    "    _tempDf = pd.DataFrame(df.groupby(groupby_lst)[field].rolling(n_months).mean().reset_index())\n",
    "    return _tempDf.groupby(groupby_lst)[field].shift(1)\n",
    "\n",
    "def f(x):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    elif x == 1:\n",
    "        return 1\n",
    "    elif x == 3:\n",
    "        return 2  \n",
    "    \n",
    "def h_goals(row):\n",
    "    if (row['was_home'] == 1):\n",
    "        return row['goals_for']\n",
    "    else:\n",
    "        return 0 \n",
    "    \n",
    "def a_goals(row):\n",
    "    if (row['was_home'] == 0):\n",
    "        return row['goals_for']\n",
    "    else:\n",
    "        return 0 \n",
    "    \n",
    "df= pd.read_sql(\"\"\" CALL `epl`.`sp_match_agg_avg_curr`(); \"\"\", con=connection)\n",
    "team_lookup = pd.read_sql(\"\"\" SELECT code as id, name FROM epl.tbl_team_info_2018_2019; \"\"\", con=connection)  \n",
    "\n",
    "df['sf'] = str(df['fixture']) + df['season']\n",
    "\n",
    " \n",
    "df['y_vector'] = df.apply(lambda row: f(row['result']), axis=1)\n",
    "\n",
    "df['win_a'] = df['result'].apply(lambda x: 1 if x == 3 else 0)\n",
    "df['draw_a'] = df['result'].apply(lambda x: 1 if x == 1 else 0)\n",
    "df['loss_a'] = df['result'].apply(lambda x: 1 if x == 0 else 0)\n",
    "\n",
    "\n",
    "filedOrder = ['season','team_id']\n",
    "numRoll = 3\n",
    "\n",
    "df['sf'] = df['fixture'].apply(str) + df['season']\n",
    "df['kp_avg'] = rolled_mean(df,filedOrder,'key_passes',numRoll,1)\n",
    "df['atp_var'] = df.big_chances_created + df.big_chances_missed + df.target_missed\n",
    "df['atp_avg'] = rolled_mean(df,filedOrder,'atp_var',numRoll,1)\n",
    "df['cbi_avg'] = rolled_mean(df,filedOrder,'clearances_blocks_interceptions',numRoll,1)\n",
    "df['bcc_avg'] = rolled_mean(df,filedOrder,'big_chances_created',numRoll,1)\n",
    "df['bcm_avg'] = rolled_mean(df,filedOrder,'big_chances_missed',numRoll,1)\n",
    "df['gf_avg'] = rolled_mean(df,filedOrder,'goals_for',numRoll,1)\n",
    "df['a_avg'] = rolled_mean(df,filedOrder,'assists',numRoll,1)\n",
    "df['cp_avg'] = rolled_mean(df,filedOrder,'completed_passes',numRoll,1)\n",
    "df['ap_avg'] = rolled_mean(df,filedOrder,'attempted_passes',numRoll,1)\n",
    "df['ap_avg_sq'] = df['ap_avg']**2 \n",
    "df['pa_avg'] = df['cp_avg']/df['ap_avg']\n",
    "df['elg_avg'] = rolled_mean(df,filedOrder,'errors_leading_to_goal',numRoll,1)\n",
    "df['f_avg'] = rolled_mean(df,filedOrder,'fouls',numRoll,1)\n",
    "df['r_avg'] = rolled_mean(df,filedOrder,'recoveries',numRoll,1)\n",
    "df['s_avg'] = rolled_mean(df,filedOrder,'saves',numRoll,1)\n",
    "df['bps_avg'] = rolled_mean(df,filedOrder,'bps',numRoll,1)\n",
    "df['tgm_avg'] = rolled_mean(df,filedOrder,'target_missed',numRoll,1)\n",
    "df['cs_avg'] = cum_sum(df,filedOrder,'clean_sheets')\n",
    "df['win'] = cum_sum(df,filedOrder,'win_a')\n",
    "df['draw'] = cum_sum(df,filedOrder,'draw_a')\n",
    "df['loss'] = cum_sum(df,filedOrder,'loss_a')\n",
    "df['points'] = cum_sum(df,filedOrder,'result')\n",
    "df['goals_for_reg'] = df['goals_for'] \n",
    "df['goals_ag_reg'] = df['goals_against'] \n",
    "df['goals_for'] = cum_sum(df,filedOrder,'goals_for')  \n",
    "df['goals_against'] = cum_sum(df,filedOrder,'goals_against')  \n",
    "df['goaldiff'] = cum_sum(df,filedOrder,'goals_for')  - cum_sum(df,filedOrder,'goals_against')  \n",
    "\n",
    "df['h_gf'] = df.apply(h_goals, axis=1)\n",
    "df['h_gf'] = cum_sum(df,filedOrder,'h_gf')\n",
    "\n",
    "\n",
    "df['a_gf'] = df.apply(a_goals, axis=1)\n",
    "df['a_gf'] = cum_sum(df,filedOrder,'a_gf')\n",
    "\n",
    "prev = next(df.iterrows())[1]\n",
    "win_streak = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['match_day'] == 1 and row['result']== 3:\n",
    "        streak = 1\n",
    "        win_streak.append(streak)\n",
    "    elif row['match_day'] == 1 and row['result'] != 3:\n",
    "        streak =0\n",
    "        win_streak.append(streak)\n",
    "    elif prev['result'] != 3 and row['result'] ==2:\n",
    "        streak = 1\n",
    "        win_streak.append(streak)\n",
    "    elif prev['result'] == 3 and row['result'] ==3:\n",
    "        streak += 1\n",
    "        win_streak.append(streak)\n",
    "    else:\n",
    "        streak = 0\n",
    "        win_streak.append(streak)\n",
    "    prev = row\n",
    "    \n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "encoder = LabelEncoder ()   \n",
    "    \n",
    "    \n",
    "df['winstreak'] = win_streak\n",
    "df['winstreak'] = df.groupby(filedOrder)['winstreak'].shift(1)\n",
    "\n",
    "\n",
    "xgprep = df.dropna(subset=['cp_avg','ap_avg','ap_avg_sq','pa_avg','kp_avg','atp_avg'])\n",
    "\n",
    "xg_df = pd.DataFrame(np.float64(regressor.predict(\n",
    "                     scaler.fit_transform(xgprep[['cp_avg','ap_avg','ap_avg_sq','pa_avg','kp_avg','atp_avg']]))),index=xgprep.index,columns=['xG'])\n",
    "\n",
    "df = pd.merge(df, xg_df, how='left', left_index=True, right_index=True)\n",
    "\n",
    "home_df = pd.merge(df.where(df['was_home']== 1).dropna(), df.where(df['was_home']== 0).dropna(), how='inner', on=['sf'])\n",
    "away_df = pd.merge(df.where(df['was_home']== 0).dropna(), df.where(df['was_home']== 1).dropna(), how='inner', on=['sf'])\n",
    "all_df = pd.concat([home_df,away_df])\n",
    "\n",
    "h_prep_df= (home_df[['sf','team_id_x', 'team_id_y', 'season_x','match_day_x','y_vector_x', 'goaldiff_x',\n",
    "                      'ap_avg_x','xG_x','cp_avg_x','win_x','pa_avg_x','goals_for_x','goaldiff_y','pa_avg_y',\n",
    "                      'ap_avg_y','cp_avg_y','xG_y']].dropna())\n",
    "\n",
    "a_prep_df= (away_df[['y_vector_x','winstreak_x','sf','team_id_x','goaldiff_x','cp_avg_x','ap_avg_x','pa_avg_x','bps_avg_x',\n",
    "                     'a_avg_x','ap_avg_y','cp_avg_y','goaldiff_y','pa_avg_y','win_y','loss_x']].dropna()) \n",
    " \n",
    "\n",
    "#learn_prep_df['rslt_num'] = encoder.fit_transform(learn_prep_df['result_x'])\n",
    "X_h = h_prep_df\n",
    "Y_h = h_prep_df[['y_vector_x','sf']]\n",
    "\n",
    "X_a = a_prep_df[[ 'sf','team_id_x','winstreak_x','goaldiff_x','cp_avg_x','ap_avg_x','pa_avg_x','bps_avg_x',\n",
    "                     'a_avg_x','ap_avg_y','cp_avg_y','goaldiff_y','pa_avg_y','win_y','loss_x']]\n",
    "\n",
    "#X = pd.DataFrame(scaler.fit_transform(X), index=X.index, columns=X.columns) \n",
    "X_h_train, X_h_test, Y_h_train, Y_h_test = train_test_split(X_h, Y_h, test_size=0.40,shuffle=True)\n",
    "\n",
    "X_a_train = a_prep_df[a_prep_df['sf'].isin(X_h_train['sf'])].drop(columns=['y_vector_x','team_id_x','sf']) \n",
    "X_a_test = a_prep_df[a_prep_df['sf'].isin(X_h_test['sf'])].drop(columns=['y_vector_x','team_id_x','sf']) \n",
    "Y_a_train = a_prep_df[a_prep_df['sf'].isin(Y_h_train['sf'])]['y_vector_x']\n",
    "Y_a_test =  a_prep_df[a_prep_df['sf'].isin(Y_h_test['sf'])]['y_vector_x']\n",
    "\n",
    "X_h_train = X_h_train.drop(columns=['sf','team_id_x', 'team_id_y', 'season_x','match_day_x','y_vector_x']) \n",
    "X_h_test = X_h_test.drop(columns=['sf','team_id_x', 'team_id_y', 'season_x','match_day_x','y_vector_x'])\n",
    "Y_h_train = Y_h_train.drop(columns=['sf'])\n",
    "Y_h_test = Y_h_test.drop(columns=['sf'])\n",
    "\n",
    "\n",
    "X_a_train = pd.DataFrame(scaler.fit_transform(X_a_train), index=X_a_train.index, columns=X_a_train.columns) \n",
    "X_a_test = pd.DataFrame(scaler.fit_transform(X_a_test), index=X_a_test.index, columns=X_a_test.columns) \n",
    "X_h_train = pd.DataFrame(scaler.fit_transform(X_h_train), index=X_h_train.index, columns=X_h_train.columns) \n",
    "X_h_test = pd.DataFrame(scaler.fit_transform(X_h_test), index=X_h_test.index, columns=X_h_test.columns) \n",
    "\n",
    "#For Keras\n",
    "Y_keras_train = to_categorical(Y_h_train, num_classes=None)\n",
    "Y_keras_test = to_categorical(Y_h_test, num_classes=None)\n",
    "\n",
    "qgrid.show_grid(h_prep_df.corr(),grid_options=grid_options,precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Visualizing Correlations with Bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import *\n",
    "from bokeh.layouts import column, row, widgetbox\n",
    "from bokeh.models import CustomJS,HoverTool,ColumnDataSource\n",
    "from bokeh.palettes import d3\n",
    "from bokeh.transform import factor_cmap, factor_mark\n",
    "from bokeh.models.widgets import CheckboxGroup\n",
    "output_notebook()\n",
    "\n",
    "h_prep_df2 = pd.merge(team_lookup,home_df, how='inner', left_on=['id'], right_on=['team_id_x'])\n",
    "h_prep_df2 = pd.merge(h_prep_df2,team_lookup, how='inner', left_on=['team_id_y'], right_on=['id'])\n",
    "\n",
    "tools = \"pan,wheel_zoom,box_zoom,reset,save\"\n",
    "                 \n",
    "def cats(x):\n",
    "    if x == 0:\n",
    "        return \"Loss\"\n",
    "    elif x == 1:\n",
    "        return \"Draw\"\n",
    "    elif x == 2:\n",
    "        return \"Win\"\n",
    "\n",
    "h_prep_df2['label'] =  h_prep_df2['y_vector_x'].apply(cats)  \n",
    "\n",
    "hover = HoverTool(tooltips=[\n",
    "    (\"Team\", \"@name_x\"),\n",
    "    (\"Opponent\", \"@name_y\"),\n",
    "    (\"Season\", \"@season_x\"),\n",
    "    (\"Match Day\", \"@match_day_x\"),\n",
    "    (\"(Expected Goals, Expected Goals Opp)\", \"(@xG_x, @xG_y)\"),\n",
    "    ('Result', '@label'),\n",
    "])\n",
    "\n",
    "source = ColumnDataSource(h_prep_df2)\n",
    "orig_source = ColumnDataSource(h_prep_df2)\n",
    "\n",
    "checkbox = CheckboxGroup(labels=h_prep_df2.name_y.unique().tolist())\n",
    "\n",
    "x = 'xG_x'\n",
    "y = 'xG_y'\n",
    " \n",
    "\n",
    "checkbox.callback = CustomJS(args=dict(labels=checkbox.labels,source=source,orig=orig_source,x=x,y=y), code=\"\"\"\n",
    "   \n",
    "    const d = orig.data;\n",
    "    var n;\n",
    "    currentLabels = []\n",
    "    for (n in cb_obj.active){\n",
    "             currentLabels.push(labels[cb_obj.active[n]])\n",
    "    }     \n",
    "    \n",
    "    var index = [] \n",
    "    \n",
    "    for (l in currentLabels) {    \n",
    "        for(indx in d['name_x']){\n",
    "            if (d['name_x'][indx] == currentLabels[l]) {\n",
    "                index.push(indx)\n",
    "            }\n",
    "        }\n",
    " \n",
    "    }   \n",
    "        var temp = []        \n",
    "        for (var col in orig.data){\n",
    "            for (var i = 0; i < index.length; i++) {\n",
    "                 temp.push(orig.data[col][index[i]])\n",
    "                 }\n",
    "                 source.data[col] = temp\n",
    "                 console.log(source.data)\n",
    "                 temp = []\n",
    "            } \n",
    "        \n",
    "         \n",
    "        source.change.emit();\n",
    "   \n",
    "\"\"\")\n",
    "\n",
    "#team_selection.js_on_change('active',update)\n",
    "\n",
    "palette = d3['Category20'][len(h_prep_df2.name_x.unique())]\n",
    "MARKERS = ['x', 'circle', 'triangle']\n",
    "\n",
    "p = figure(plot_width=850, plot_height=600,tools=tools)\n",
    "p.add_tools(hover)\n",
    "\n",
    "\n",
    "\n",
    "p.scatter(x=x, y=y,size=10,\n",
    "          color=factor_cmap('name_x', palette, h_prep_df2.name_x.unique()),\n",
    "          marker=factor_mark('label', MARKERS, h_prep_df2.label.unique()),\n",
    "          legend='label', source=source)\n",
    "layout = row(p, widgetbox(checkbox))\n",
    "\n",
    "show(layout)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected Goals Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.dropna()\n",
    "\n",
    "X_h = X[['cp_avg','ap_avg','ap_avg_sq','pa_avg','kp_avg','atp_avg']]\n",
    "Y_h= X[['goals_for_reg']]\n",
    "    \n",
    "X_h_train, X_h_test, Y_h_train, Y_h_test = train_test_split(X_h, Y_h, test_size=0.30,shuffle=True)\n",
    "\n",
    "X_h_train = pd.DataFrame(scaler.fit_transform(X_h_train), index=X_h_train.index, columns=X_h_train.columns) \n",
    "X_h_test = pd.DataFrame(scaler.fit_transform(X_h_test), index=X_h_test.index, columns=X_h_test.columns) \n",
    "\n",
    "regressor = Sequential()\n",
    "regressor.add(Dense(units=4, input_dim=6))\n",
    "regressor.add(Dense(units=2))\n",
    "regressor.add(Dense(units=1))\n",
    "regressor.compile(optimizer='adam', loss='mean_squared_error',  metrics=['mae','accuracy'])\n",
    "regressor.fit(X_h_train, Y_h_train, epochs=1000, batch_size=40, verbose=2)\n",
    "\n",
    "regressor_json = regressor.to_json()\n",
    "with open(\"regressor.json\", \"w\") as json_file:\n",
    "    json_file.write(regressor_json)\n",
    "# serialize weights to HDF5\n",
    "regressor.save_weights(\"regressor.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Keras NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=len(X_h_train.columns), activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "\n",
    "model.fit(X_h_train, Y_keras_train, epochs=10000, batch_size=40)\n",
    "\n",
    "\n",
    "predictions = model.predict_classes(X_h_test)\n",
    "predictions\n",
    "prd_df = pd.DataFrame(predictions, index=X_h_test.index, columns=['pred']) \n",
    "\n",
    "cm= confusion_matrix(Y_h_test, predictions)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Game Predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentSeason = df.where(df.season == max(df.season)).dropna(how='all') \n",
    "nextGames = currentSeason.where(currentSeason.match_day == max(currentSeason.match_day)).dropna(how='all') \n",
    "ng_tp = pd.merge(nextGames.where(nextGames['was_home']== 1).dropna(how='all') , nextGames.where(df['was_home']== 0).dropna(how='all') , how='inner', on=['sf'])\n",
    "ng_tp = pd.merge(team_lookup,ng_tp, how='inner', left_on=['id'], right_on=['opponent_team_id_x'])\n",
    "ng_tp = pd.merge(team_lookup,ng_tp, how='inner', left_on=['id'], right_on=['team_id_x'])\n",
    "ng_tp_prep = ng_tp[X_h_train.columns] \n",
    "ng_tp_prep = pd.DataFrame(scaler.fit_transform(ng_tp_prep), index=ng_tp_prep.index, columns=ng_tp_prep.columns) \n",
    "\n",
    "predictions = model.predict_proba(ng_tp_prep)\n",
    "prd_df = pd.DataFrame(predictions, index=ng_tp_prep.index, columns=['Loss','Draw','Win']) \n",
    "prd_df = pd.merge(ng_tp[['name_x','name_y']],prd_df, how='inner', left_index=True, right_index=True)\n",
    "qgrid.show_grid(prd_df,grid_options=grid_options,precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "              "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
